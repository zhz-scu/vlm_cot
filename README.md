# VLM CoT with Qwen2.5-VL-3B-Instruct

åŸºäº Qwen/Qwen2.5-VL-3B-Instruct çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰æ¨ç†è„šæœ¬ã€‚

**âœ¨ Mac MPS ä¼˜åŒ–ç‰ˆæœ¬** - é’ˆå¯¹ Apple Silicon Mac è¿›è¡Œäº†ç‰¹åˆ«ä¼˜åŒ–ï¼Œæ”¯æŒ Metal Performance Shaders (MPS) åŠ é€Ÿã€‚

## å®‰è£…

1. Python >= 3.9
2. å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

å¯é€‰ï¼šå®‰è£… `flash-attn` ä»¥åŠ é€Ÿï¼ˆæŒ‰éœ€ï¼ŒGPUç¯å¢ƒï¼‰ï¼š

```bash
pip install flash-attn --no-build-isolation
```

## è¿è¡Œ

è„šæœ¬è·¯å¾„ï¼š`src/infer_cot.py`

- å¿…éœ€å‚æ•°ï¼š`--image`ï¼ˆå¯å¤šæ¬¡ä¼ å…¥ï¼‰ï¼Œæ”¯æŒæœ¬åœ°è·¯å¾„æˆ–URLã€‚
- å¸¸ç”¨å‚æ•°ï¼š`--question`ã€`--cot-style`ã€`--max-new-tokens`ã€`--temperature`ã€`--top-p`ã€`--device`ã€`--dtype`ã€‚

### Mac MPS ä½¿ç”¨ç¤ºä¾‹

**æ¨èé…ç½®ï¼ˆMac MPS åŠ é€Ÿï¼‰ï¼š**

```bash
python src/infer_cot.py \
  --image https://raw.githubusercontent.com/QwenLM/Qwen2-VL/master/examples/images/ocr_1.jpg \
  --question "è¯·é€æ­¥è¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶æ€»ç»“è¦ç‚¹" \
  --cot-style rationale_and_answer \
  --device mps --dtype fp16 \
  --max-new-tokens 512 --temperature 0.2 --top-p 0.9
```

**è‡ªåŠ¨è®¾å¤‡é€‰æ‹©ï¼ˆæ¨èï¼‰ï¼š**

```bash
python src/infer_cot.py \
  --image image1.jpg --image image2.jpg \
  --question "ä¸¤å¼ å›¾ç‰‡çš„å…±åŒç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ" \
  --cot-style short_answer \
  --device auto --dtype auto
```

### å…¶ä»–ç¤ºä¾‹

ç¤ºä¾‹1ï¼šå•å›¾CoTï¼ˆæ˜¾å¼"æ€è€ƒè¿‡ç¨‹+æœ€ç»ˆç­”æ¡ˆ"ï¼‰

```bash
python src/infer_cot.py \
  --image https://raw.githubusercontent.com/QwenLM/Qwen2-VL/master/examples/images/ocr_1.jpg \
  --question "è¯·é€æ­¥è¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶æ€»ç»“è¦ç‚¹" \
  --cot-style rationale_and_answer \
  --max-new-tokens 512 --temperature 0.2 --top-p 0.9
```

ç¤ºä¾‹2ï¼šå¤šå›¾æ¨ç†ï¼ˆéšè—ä¸­é—´æ¨ç†ï¼Œä»…è¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼‰

```bash
python src/infer_cot.py \
  --image image1.jpg --image image2.jpg \
  --question "ä¸¤å¼ å›¾ç‰‡çš„å…±åŒç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ" \
  --cot-style short_answer
```

ç¤ºä¾‹3ï¼šä»¥JSONè¾“å‡º

```bash
python src/infer_cot.py \
  --image some.jpg \
  --question "å›¾ä¸­æ—¶é—´ä¸åœ°ç‚¹æ¨æ–­ï¼Ÿ" \
  --cot-style rationale_and_answer \
  --json
```

## Mac MPS ä¼˜åŒ–è¯´æ˜

### è®¾å¤‡é€‰æ‹©ç­–ç•¥
- `--device auto`ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
  - Mac with Apple Silicon â†’ MPS
  - NVIDIA GPU â†’ CUDA  
  - å…¶ä»– â†’ CPU
- `--device mps`ï¼šå¼ºåˆ¶ä½¿ç”¨ MPSï¼ˆMac æ¨èï¼‰
- `--device cpu`ï¼šå¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆè°ƒè¯•ç”¨ï¼‰

### æ•°æ®ç±»å‹ä¼˜åŒ–
- `--dtype auto`ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç²¾åº¦
  - MPS â†’ float16ï¼ˆæ¨èï¼‰
  - CUDA â†’ bfloat16
  - CPU â†’ float32
- `--dtype fp16`ï¼šå¼ºåˆ¶ä½¿ç”¨ float16ï¼ˆMPS æœ€ä½³æ€§èƒ½ï¼‰

### æ€§èƒ½å»ºè®®
1. **é¦–æ¬¡è¿è¡Œ**ï¼šä½¿ç”¨ `--device cpu` éªŒè¯åŠŸèƒ½
2. **æ­£å¸¸ä½¿ç”¨**ï¼šä½¿ç”¨ `--device mps --dtype fp16` è·å¾—æœ€ä½³æ€§èƒ½
3. **å†…å­˜ä¸è¶³**ï¼šé™ä½ `--max-new-tokens` æˆ–ä½¿ç”¨ `--device cpu`

## æ–‡æ¡£
- [ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—](docs/USAGE_GUIDE.md) - å®Œæ•´çš„ä½¿ç”¨è¯´æ˜å’Œç¤ºä¾‹
- [ğŸ”¬ æŠ€æœ¯ç™½çš®ä¹¦](docs/TECHNICAL_WHITEPAPER.md) - æŠ€æœ¯æ¶æ„å’Œåˆ›æ–°ç‚¹

## å¤‡æ³¨
- `--device auto` ä¼šè‡ªåŠ¨é€‰æ‹© `cuda` > `mps` > `cpu`ã€‚
- `--dtype auto`ï¼šCUDAé»˜è®¤ `bf16`ï¼ŒMPSé»˜è®¤ `fp16`ï¼ŒCPUé»˜è®¤ `fp32`ã€‚
- æ¨¡å‹é»˜è®¤ï¼š`Qwen/Qwen2.5-VL-3B-Instruct`ï¼Œå¦‚éœ€æœ¬åœ°æƒé‡ï¼Œä¼ å…¥ `--model-id /path/to/model`ã€‚

## æ•°æ®ä¸æ ¼å¼
è„šæœ¬å†…éƒ¨ä½¿ç”¨ `processor.apply_chat_template` å’Œ `qwen_vl_utils.process_vision_info` å¤„ç†å›¾åƒä¸å¤šè½®æ¶ˆæ¯ï¼Œæ¶ˆæ¯æ ¼å¼ï¼š

```json
[
  {
    "role": "user",
    "content": [
      {"type": "image", "image": "<path-or-url>"},
      {"type": "text",  "text":  "<prompt>"}
    ]
  }
]
```

`--cot-style` å–å€¼ï¼š
- `rationale_and_answer`: è¾“å‡º"æ€è€ƒè¿‡ç¨‹ï¼šâ€¦\næœ€ç»ˆç­”æ¡ˆï¼šâ€¦"ã€‚
- `short_answer`: éšè—ä¸­é—´æ¨ç†ï¼Œä»…è¾“å‡ºä¸€å¥è¯ç­”æ¡ˆã€‚
- `free`: ä½¿ç”¨ä½ æä¾›çš„ `--question` åŸæ–‡ã€‚

## å¸¸è§é—®é¢˜

### Mac ç›¸å…³é—®é¢˜
- **MPS ä¸å¯ç”¨**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨å›é€€åˆ° CPUï¼Œæ£€æŸ¥ macOS ç‰ˆæœ¬æ˜¯å¦æ”¯æŒ MPS
- **é¦–æ¬¡è¿è¡Œæ…¢**ï¼šMPS éœ€è¦é¢„çƒ­ï¼Œåç»­è¿è¡Œä¼šæ›´å¿«
- **å†…å­˜ä¸è¶³**ï¼šå°è¯•é™ä½ `--max-new-tokens` æˆ–ä½¿ç”¨ `--device cpu`

### é€šç”¨é—®é¢˜
- æ˜¾å­˜ä¸è¶³ï¼šå°è¯•é™ä½ `--max-new-tokens`ã€`--temperature`ï¼Œæˆ–æ”¹ç”¨ `--device cpu` ä»¥åšåŠŸèƒ½éªŒè¯ã€‚
- ç½‘ç»œå›¾ç‰‡403ï¼šè¯·æ”¹ç”¨å¯å…¬å¼€è®¿é—®çš„URLæˆ–ä¸‹è½½ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„ã€‚
- æ¨¡å‹ä¸‹è½½æ…¢ï¼šä½¿ç”¨ `HF_ENDPOINT=https://hf-mirror.com` ç¯å¢ƒå˜é‡åŠ é€Ÿä¸‹è½½ã€‚

### è°ƒè¯•æŠ€å·§
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python src/infer_cot.py --image test.jpg --question "test" --device cpu 2>&1 | tee debug.log

# æ£€æŸ¥è®¾å¤‡çŠ¶æ€
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('MPS:', hasattr(torch.backends, 'mps') and torch.backends.mps.is_available())"
```
