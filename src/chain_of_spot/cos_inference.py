#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chain-of-Spot æ¨ç†è„šæœ¬

åŸºäºè®ºæ–‡å®ç°çš„äº¤äº’å¼æ¨ç†æ–¹æ³•ï¼Œé€šè¿‡ä¸¤æ­¥æ¨ç†è¿‡ç¨‹ï¼š
1. è¯†åˆ«å›¾åƒä¸­çš„å…³æ³¨åŒºåŸŸ (ROI)
2. åŸºäºROIå’ŒåŸå›¾ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
"""

import argparse
import json
import sys
import torch
from pathlib import Path
from PIL import Image
from typing import List, Dict, Any
from transformers import AutoProcessor

try:
    from transformers import Qwen2_5_VLForConditionalGeneration
    HAS_NATIVE_QWEN25_VL = True
except ImportError:
    from transformers import AutoModelForCausalLM
    Qwen2_5_VLForConditionalGeneration = None
    HAS_NATIVE_QWEN25_VL = False

from cos_model import ChainOfSpotModel, CoSResponse


def load_model_and_processor(model_id: str, device: str, dtype_str: str):
    """åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨"""
    # è®¾å¤‡é€‰æ‹©
    if device == "auto":
        if torch.cuda.is_available():
            device = "cuda"
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            device = "mps"
        else:
            device = "cpu"
    
    # æ•°æ®ç±»å‹é€‰æ‹©
    if dtype_str == "auto":
        torch_dtype = torch.float16 if device == "mps" else torch.float32
    else:
        dtype_mapping = {"bf16": torch.bfloat16, "fp16": torch.float16, "fp32": torch.float32}
        torch_dtype = dtype_mapping.get(dtype_str, torch.float32)
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}, æ•°æ®ç±»å‹: {torch_dtype}", file=sys.stderr)
    
    # åŠ è½½æ¨¡å‹
    if HAS_NATIVE_QWEN25_VL:
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_id, torch_dtype=torch_dtype, device_map="auto"
        )
        processor = AutoProcessor.from_pretrained(model_id)
    else:
        model = AutoModelForCausalLM.from_pretrained(
            model_id, torch_dtype=torch_dtype, device_map="auto", trust_remote_code=True
        )
        processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
    
    print("æ¨¡å‹åŠ è½½æˆåŠŸ", file=sys.stderr)
    return model, processor, device


def cos_generate(
    model_id: str,
    image_path: str,
    question: str,
    device: str = "auto",
    dtype_str: str = "auto",
    max_new_tokens: int = 512,
    seed: int = None,
    save_roi_visualization: bool = False,
    output_dir: str = ".",
) -> Dict[str, Any]:
    """
    Chain-of-Spot ç”Ÿæˆå‡½æ•°
    
    Args:
        model_id: æ¨¡å‹ID
        image_path: å›¾åƒè·¯å¾„
        question: é—®é¢˜
        device: è®¾å¤‡
        dtype_str: æ•°æ®ç±»å‹
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        seed: éšæœºç§å­
        save_roi_visualization: æ˜¯å¦ä¿å­˜ROIå¯è§†åŒ–
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        Dict: åŒ…å«æ¨ç†ç»“æœçš„å­—å…¸
    """
    if seed is not None:
        torch.manual_seed(seed)
    
    # åŠ è½½æ¨¡å‹
    model, processor, device = load_model_and_processor(model_id, device, dtype_str)
    
    # åˆå§‹åŒ–Chain-of-Spotæ¨¡å‹
    cos_model = ChainOfSpotModel(model, processor, device)
    
    # åŠ è½½å›¾åƒ
    try:
        image = Image.open(image_path).convert("RGB")
        print(f"å›¾åƒåŠ è½½æˆåŠŸ: {image.size}", file=sys.stderr)
    except Exception as e:
        print(f"å›¾åƒåŠ è½½å¤±è´¥: {e}", file=sys.stderr)
        raise
    
    # æ‰§è¡Œäº¤äº’å¼æ¨ç†
    print("å¼€å§‹Chain-of-Spotæ¨ç†...", file=sys.stderr)
    response = cos_model.interactive_reasoning(image, question)
    
    # ä¿å­˜ROIå¯è§†åŒ–
    if save_roi_visualization:
        try:
            roi_viz = cos_model.image_cropper.visualize_roi(image, response.roi_bbox)
            viz_path = Path(output_dir) / "roi_visualization.png"
            roi_viz.save(viz_path)
            print(f"ROIå¯è§†åŒ–å·²ä¿å­˜: {viz_path}", file=sys.stderr)
        except Exception as e:
            print(f"ROIå¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}", file=sys.stderr)
    
    # æ„å»ºè¿”å›ç»“æœ
    result = {
        "method": "Chain-of-Spot",
        "question": question,
        "image_path": image_path,
        "roi_bbox": response.roi_bbox.to_string(),
        "final_answer": response.final_answer,
        "reasoning_trace": response.reasoning_trace,
        "confidence": response.confidence,
        "interactive_reasoning": True
    }
    
    print("Chain-of-Spotæ¨ç†å®Œæˆ", file=sys.stderr)
    return result


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Chain-of-Spot: Interactive Reasoning for Large Vision-Language Models"
    )
    
    parser.add_argument("--model-id", type=str, default="Qwen/Qwen2.5-VL-3B-Instruct",
                       help="æ¨¡å‹IDæˆ–è·¯å¾„")
    parser.add_argument("--image", type=str, required=True,
                       help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--question", type=str, required=True,
                       help="è¦è¯¢é—®çš„é—®é¢˜")
    parser.add_argument("--device", type=str, default="auto",
                       choices=["auto", "cuda", "mps", "cpu"],
                       help="æ¨ç†è®¾å¤‡")
    parser.add_argument("--dtype", type=str, default="auto",
                       choices=["auto", "bf16", "fp16", "fp32"],
                       help="æ•°æ®ç±»å‹")
    parser.add_argument("--max-new-tokens", type=int, default=512,
                       help="æœ€å¤§ç”Ÿæˆtokenæ•°")
    parser.add_argument("--seed", type=int, default=None,
                       help="éšæœºç§å­")
    parser.add_argument("--save-roi-viz", action="store_true",
                       help="ä¿å­˜ROIå¯è§†åŒ–")
    parser.add_argument("--output-dir", type=str, default=".",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--json", action="store_true",
                       help="JSONæ ¼å¼è¾“å‡º")
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    try:
        result = cos_generate(
            model_id=args.model_id,
            image_path=args.image,
            question=args.question,
            device=args.device,
            dtype_str=args.dtype,
            max_new_tokens=args.max_new_tokens,
            seed=args.seed,
            save_roi_visualization=args.save_roi_viz,
            output_dir=args.output_dir,
        )
        
        if args.json:
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print("=" * 80)
            print("ğŸ” Chain-of-Spot äº¤äº’å¼æ¨ç†ç»“æœ")
            print("=" * 80)
            print(f"é—®é¢˜: {result['question']}")
            print(f"å›¾åƒ: {result['image_path']}")
            print(f"ROIåŒºåŸŸ: {result['roi_bbox']}")
            print(f"æœ€ç»ˆç­”æ¡ˆ: {result['final_answer']}")
            print(f"ç½®ä¿¡åº¦: {result['confidence']:.3f}")
            
            print("\nğŸ“ æ¨ç†è½¨è¿¹:")
            for i, trace in enumerate(result['reasoning_trace'], 1):
                print(f"{i}. {trace}")
            
            print("\nâœ¨ æ–¹æ³•ç‰¹ç‚¹:")
            print("- ğŸ¯ äº¤äº’å¼æ¨ç†: åŠ¨æ€è¯†åˆ«å…³æ³¨åŒºåŸŸ")
            print("- ğŸ” ä¸¤æ­¥æ¨ç†: ROIå®šä½ + ç»†èŠ‚åˆ†æ")
            print("- ğŸ“Š å¤šç²’åº¦ç‰¹å¾: ä¿æŒåŸå›¾åˆ†è¾¨ç‡çš„åŒæ—¶å…³æ³¨ç»†èŠ‚")
            print("- ğŸš€ æ€§èƒ½æå‡: åœ¨å¤šä¸ªå¤šæ¨¡æ€æ•°æ®é›†ä¸Šè¾¾åˆ°SOTA")
            
    except Exception as e:
        print(f"æ¨ç†å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
