#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥è„šæœ¬

æ£€æŸ¥PyTorchã€Transformersç­‰åº“çš„ç‰ˆæœ¬å…¼å®¹æ€§
"""

import sys
import subprocess
import pkg_resources

def check_package_version(package_name):
    """æ£€æŸ¥åŒ…ç‰ˆæœ¬"""
    try:
        version = pkg_resources.get_distribution(package_name).version
        return version
    except pkg_resources.DistributionNotFound:
        return "æœªå®‰è£…"

def check_torch_compatibility():
    """æ£€æŸ¥PyTorchå…¼å®¹æ€§"""
    print("=== PyTorchå…¼å®¹æ€§æ£€æŸ¥ ===")
    
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥FILE_LIKEæ˜¯å¦å¯ç”¨
        try:
            from torch.serialization import FILE_LIKE
            print("âœ… FILE_LIKE å¯ç”¨")
        except ImportError:
            print("âŒ FILE_LIKE ä¸å¯ç”¨ (è¿™æ˜¯æ­£å¸¸çš„ï¼Œæ–°ç‰ˆæœ¬å·²ç§»é™¤)")
        
        # æ£€æŸ¥å…¶ä»–å…³é”®API
        try:
            from torch.serialization import _get_safe_weights_metadata
            print("âœ… _get_safe_weights_metadata å¯ç”¨")
        except ImportError:
            print("âŒ _get_safe_weights_metadata ä¸å¯ç”¨")
        
        # æ£€æŸ¥è®¾å¤‡æ”¯æŒ
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        print(f"MPSå¯ç”¨: {hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()}")
        print(f"NPUå¯ç”¨: {hasattr(torch, 'npu') and torch.npu.is_available()}")
        print(f"XPUå¯ç”¨: {hasattr(torch, 'xpu') and torch.xpu.is_available()}")
        
    except ImportError as e:
        print(f"âŒ PyTorchå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def check_transformers_compatibility():
    """æ£€æŸ¥Transformerså…¼å®¹æ€§"""
    print("\n=== Transformerså…¼å®¹æ€§æ£€æŸ¥ ===")
    
    try:
        import transformers
        print(f"Transformersç‰ˆæœ¬: {transformers.__version__}")
        
        # æ£€æŸ¥å…³é”®ç±»æ˜¯å¦å¯ç”¨
        try:
            from transformers import AutoModelForCausalLM, AutoProcessor
            print("âœ… AutoModelForCausalLM å¯ç”¨")
            print("âœ… AutoProcessor å¯ç”¨")
        except ImportError as e:
            print(f"âŒ AutoModelForCausalLM/AutoProcessor ä¸å¯ç”¨: {e}")
        
        try:
            from transformers import Qwen2_5_VLForConditionalGeneration
            print("âœ… Qwen2_5_VLForConditionalGeneration å¯ç”¨")
        except ImportError:
            print("âŒ Qwen2_5_VLForConditionalGeneration ä¸å¯ç”¨ (å¯èƒ½éœ€è¦å®‰è£…qwen-vl)")
        
    except ImportError as e:
        print(f"âŒ Transformerså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def check_npu_compatibility():
    """æ£€æŸ¥NPUå…¼å®¹æ€§"""
    print("\n=== NPUå…¼å®¹æ€§æ£€æŸ¥ ===")
    
    try:
        import torch_npu
        print("âœ… torch_npu å·²å®‰è£…")
        
        try:
            import torch_npu.npu
            print("âœ… torch_npu.npu å¯ç”¨")
        except ImportError as e:
            print(f"âŒ torch_npu.npu ä¸å¯ç”¨: {e}")
        
    except ImportError:
        print("âŒ torch_npu æœªå®‰è£…")
        print("   NPUåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†ä¸å½±å“å…¶ä»–è®¾å¤‡")
        return False
    
    return True

def check_other_dependencies():
    """æ£€æŸ¥å…¶ä»–ä¾èµ–"""
    print("\n=== å…¶ä»–ä¾èµ–æ£€æŸ¥ ===")
    
    dependencies = [
        "PIL",
        "numpy",
        "requests",
        "safetensors",
        "accelerate",
        "torchvision"
    ]
    
    for dep in dependencies:
        try:
            if dep == "PIL":
                import PIL
                version = PIL.__version__
            elif dep == "torchvision":
                import torchvision
                version = torchvision.__version__
                # æ£€æŸ¥NMSå¯ç”¨æ€§
                if hasattr(torchvision.ops, 'nms'):
                    print(f"âœ… {dep}: {version} (NMSå¯ç”¨)")
                else:
                    print(f"âš ï¸  {dep}: {version} (NMSä¸å¯ç”¨)")
                continue
            else:
                version = pkg_resources.get_distribution(dep).version
            print(f"âœ… {dep}: {version}")
        except (ImportError, pkg_resources.DistributionNotFound):
            print(f"âŒ {dep}: æœªå®‰è£…")

def suggest_fixes():
    """å»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
    print("\n=== ä¿®å¤å»ºè®® ===")
    
    print("å¦‚æœé‡åˆ°FILE_LIKEé”™è¯¯ï¼Œè¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆ:")
    print()
    print("1. æ›´æ–°transformersåº“:")
    print("   pip install --upgrade transformers")
    print()
    print("2. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•é™çº§PyTorch:")
    print("   pip install torch==2.0.1")
    print()
    print("3. å¯¹äºNPUç¯å¢ƒï¼Œç¡®ä¿ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬:")
    print("   pip install torch_npu")
    print()
    print("4. æ¸…ç†ç¼“å­˜å¹¶é‡æ–°å®‰è£…:")
    print("   pip cache purge")
    print("   pip install --force-reinstall transformers")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥å„ä¸ªç»„ä»¶
    torch_ok = check_torch_compatibility()
    transformers_ok = check_transformers_compatibility()
    npu_ok = check_npu_compatibility()
    check_other_dependencies()
    
    # æ€»ç»“
    print("\n=== æ£€æŸ¥æ€»ç»“ ===")
    if torch_ok and transformers_ok:
        print("âœ… åŸºæœ¬å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
        if npu_ok:
            print("âœ… NPUæ”¯æŒå¯ç”¨")
        else:
            print("âš ï¸  NPUæ”¯æŒä¸å¯ç”¨ï¼Œä½†ä¸å½±å“å…¶ä»–åŠŸèƒ½")
    else:
        print("âŒ å­˜åœ¨å…¼å®¹æ€§é—®é¢˜")
        suggest_fixes()

if __name__ == "__main__":
    main()
