# VLM CoT ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
3. [å‚æ•°è¯¦è§£](#å‚æ•°è¯¦è§£)
4. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
5. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
python scripts/download_model.py
```

### 2. åŸºç¡€ä½¿ç”¨
```bash
# æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
python src/infer_cot.py \
  --image your_image.jpg \
  --question "æè¿°è¿™å¼ å›¾ç‰‡"
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### æ”¯æŒçš„ CoT é£æ ¼
1. **`rationale_and_answer`** - æ˜¾å¼æ¨ç†è¿‡ç¨‹ + æœ€ç»ˆç­”æ¡ˆ
2. **`short_answer`** - éšè—æ¨ç†ï¼Œä»…è¾“å‡ºç­”æ¡ˆ
3. **`free`** - è‡ªç”±æ ¼å¼ï¼Œä¸åŠ çº¦æŸ

### è®¾å¤‡æ”¯æŒ
- **CUDA** - NVIDIA GPU åŠ é€Ÿ
- **MPS** - Apple Silicon Mac åŠ é€Ÿï¼ˆæ¨èï¼‰
- **CPU** - é€šç”¨è®¡ç®—è®¾å¤‡

## âš™ï¸ å‚æ•°è¯¦è§£

### å¿…éœ€å‚æ•°
| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--image` | å›¾ç‰‡è·¯å¾„æˆ–URL | `--image photo.jpg` |

### å¸¸ç”¨å‚æ•°
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--question` | "è¯·é€æ­¥æ€è€ƒå¹¶å›ç­”é—®é¢˜" | è¦è¯¢é—®çš„é—®é¢˜ |
| `--cot-style` | `rationale_and_answer` | CoTè¾“å‡ºé£æ ¼ |
| `--device` | `auto` | è®¡ç®—è®¾å¤‡é€‰æ‹© |
| `--dtype` | `auto` | è®¡ç®—ç²¾åº¦ |
| `--max-new-tokens` | `512` | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `--temperature` | `0.2` | é‡‡æ ·æ¸©åº¦ |
| `--top-p` | `0.9` | æ ¸é‡‡æ ·é˜ˆå€¼ |

### é«˜çº§å‚æ•°
| å‚æ•° | è¯´æ˜ |
|------|------|
| `--model-id` | æ¨¡å‹æ ‡è¯†ï¼ˆé»˜è®¤ï¼šQwen/Qwen2.5-VL-3B-Instructï¼‰ |
| `--seed` | éšæœºç§å­ |
| `--json` | JSONæ ¼å¼è¾“å‡º |

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºç¡€å›¾ç‰‡æè¿°
```bash
python src/infer_cot.py \
  --image cat.jpg \
  --question "è¿™åªçŒ«åœ¨åšä»€ä¹ˆï¼Ÿ" \
  --cot-style rationale_and_answer
```

### ç¤ºä¾‹2ï¼šå¤šå›¾ç‰‡å¯¹æ¯”
```bash
python src/infer_cot.py \
  --image image1.jpg --image image2.jpg \
  --question "ä¸¤å¼ å›¾ç‰‡æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ" \
  --cot-style short_answer
```

### ç¤ºä¾‹3ï¼šMac MPS ä¼˜åŒ–
```bash
python src/infer_cot.py \
  --image document.jpg \
  --question "æå–å›¾ç‰‡ä¸­çš„æ–‡å­—ä¿¡æ¯" \
  --device mps --dtype fp16 \
  --max-new-tokens 256
```

### ç¤ºä¾‹4ï¼šç§‘å­¦é—®é¢˜æ¨ç†
```bash
python src/scienceqa_cot.py \
  --image science_diagram.jpg \
  --question "è§£é‡Šè¿™ä¸ªç‰©ç†ç°è±¡" \
  --context "è¿™æ˜¯ä¸€ä¸ªç”µè·¯å›¾"
```

### ç¤ºä¾‹5ï¼šé«˜çº§æ¨ç†åŠŸèƒ½
```bash
python src/advanced_cot.py \
  --image complex_image.jpg \
  --question "åˆ†æå›¾ç‰‡ä¸­çš„é€»è¾‘å…³ç³»" \
  --enable-advanced-features
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### Mac MPS ä¼˜åŒ–
```bash
# æ¨èé…ç½®
python src/infer_cot.py \
  --image your_image.jpg \
  --question "your question" \
  --device mps --dtype fp16 \
  --max-new-tokens 256
```

### å†…å­˜ä¼˜åŒ–
```bash
# é™ä½å†…å­˜ä½¿ç”¨
python src/infer_cot.py \
  --image your_image.jpg \
  --question "your question" \
  --max-new-tokens 128 \
  --device cpu
```

### æ‰¹é‡å¤„ç†
```bash
# ä½¿ç”¨è„šæœ¬è¿›è¡Œæ‰¹é‡æµ‹è¯•
python scripts/vlm_cot_test.py
```

## ğŸ”§ å¸¸è§é—®é¢˜

### è®¾å¤‡ç›¸å…³é—®é¢˜

**Q: MPS ä¸å¯ç”¨æ€ä¹ˆåŠï¼Ÿ**
```bash
# æ£€æŸ¥ MPS çŠ¶æ€
python scripts/test_mps.py

# å¼ºåˆ¶ä½¿ç”¨ CPU
python src/infer_cot.py --device cpu
```

**Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ**
```bash
# é™ä½å‚æ•°
python src/infer_cot.py \
  --max-new-tokens 64 \
  --device cpu
```

### æ¨¡å‹ç›¸å…³é—®é¢˜

**Q: æ¨¡å‹ä¸‹è½½æ…¢æ€ä¹ˆåŠï¼Ÿ**
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
python src/infer_cot.py ...

# æˆ–ä½¿ç”¨ ModelScope
python scripts/download_model.py
```

**Q: æ¨¡å‹åŠ è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
```bash
# å‡çº§ transformers
pip install --upgrade transformers

# æˆ–ä»æºç å®‰è£…
pip install git+https://github.com/huggingface/transformers
```

### å›¾ç‰‡ç›¸å…³é—®é¢˜

**Q: ç½‘ç»œå›¾ç‰‡æ— æ³•è®¿é—®ï¼Ÿ**
```bash
# ä¸‹è½½åˆ°æœ¬åœ°
curl -o local_image.jpg "https://example.com/image.jpg"
python src/infer_cot.py --image local_image.jpg
```

**Q: å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒï¼Ÿ**
```bash
# è½¬æ¢ä¸ºæ”¯æŒçš„æ ¼å¼
pip install Pillow
python -c "
from PIL import Image
img = Image.open('your_image.png')
img.save('converted.jpg', 'JPEG')
"
```

## ğŸ§ª æµ‹è¯•å’Œè°ƒè¯•

### è¿è¡Œæµ‹è¯•
```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python scripts/test_mps.py

# CoT å¯¹æ¯”æµ‹è¯•
python scripts/vlm_cot_test.py

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
python scripts/cot_final_report.py
```

### è°ƒè¯•æŠ€å·§
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python src/infer_cot.py --image test.jpg --question "test" 2>&1 | tee debug.log

# æ£€æŸ¥è®¾å¤‡çŠ¶æ€
python -c "
import torch
print('CUDA:', torch.cuda.is_available())
print('MPS:', hasattr(torch.backends, 'mps') and torch.backends.mps.is_available())
"
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### è®¾å¤‡æ€§èƒ½å¯¹æ¯”
| è®¾å¤‡ | æ¨ç†é€Ÿåº¦ | å†…å­˜ä½¿ç”¨ | æ¨èåœºæ™¯ |
|------|----------|----------|----------|
| MPS (Mac) | å¿« | ä¸­ç­‰ | æ—¥å¸¸ä½¿ç”¨ |
| CUDA (NVIDIA) | æœ€å¿« | é«˜ | æ‰¹é‡å¤„ç† |
| CPU | æ…¢ | ä½ | è°ƒè¯•/æµ‹è¯• |

### å‚æ•°å½±å“
| å‚æ•° | é€Ÿåº¦å½±å“ | è´¨é‡å½±å“ | å»ºè®® |
|------|----------|----------|------|
| `max-new-tokens` | çº¿æ€§ | æ˜¾è‘— | æ ¹æ®é—®é¢˜å¤æ‚åº¦è°ƒæ•´ |
| `temperature` | æ—  | æ˜¾è‘— | 0.1-0.3 æ¨è |
| `device` | æ˜¾è‘— | æ—  | ä¼˜å…ˆ MPS/CUDA |

## ğŸ”— ç›¸å…³èµ„æº

- [æŠ€æœ¯ç™½çš®ä¹¦](TECHNICAL_WHITEPAPER.md)
- [é¡¹ç›® README](../README.md)
- [Qwen2.5-VL å®˜æ–¹æ–‡æ¡£](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)
- [ScienceQA è®ºæ–‡](https://arxiv.org/abs/2203.10227)
